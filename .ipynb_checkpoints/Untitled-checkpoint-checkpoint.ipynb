{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "e4ee2881-d4ec-4fe8-a399-c74dbc8ae5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "3c0227d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/////////////////////////////////\n",
    "# Title: Reading and Writing to text files in Python\n",
    "# Name: N/A\n",
    "# Site Owner: Geeks for Geeks\n",
    "# Date: August 28, 2023\n",
    "# Code-Version: N/A\n",
    "# Availability: https://www.geeksforgeeks.org/reading-writing-text-files-python/\n",
    "# Modified: Yes\n",
    "file1 = open(\"hockeydata.txt\", 'w')\n",
    "START_DATE=\"2017-11-04\"\n",
    "END_DATE=\"2017-11-05\"\n",
    "rows=[]\n",
    "totalFile = []\n",
    "final_rows=[]\n",
    "initial_player_list=[]\n",
    "cols = []\n",
    "final_row = []\n",
    "total_player_list=[]\n",
    "\n",
    "HTML_PARSER = \"html.parser\"\n",
    "url = \"https://www.prosportstransactions.com/hockey/Search/SearchResults.php?Player=&Team=&BeginDate={}&EndDate={}&ILChkBx=yes&submit=Search&start={}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "b4e820ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this recieves a string and removes quotes and brace brackets\n",
    "def cleaning_results(item_to_clean):\n",
    "    if type(item_to_clean) == str:\n",
    "        item_to_clean = item_to_clean.replace('\"','')\n",
    "        item_to_clean = item_to_clean.replace('[','')\n",
    "        item_to_clean = item_to_clean.replace(\"]\",\"\")\n",
    "        item_to_clean = item_to_clean.replace(\"'\",\"\")\n",
    "    return item_to_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "5ed597ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This recieves data in the form of a string. The data is the results from the initial data collecting. This method breaks up the data into date, team,\n",
    "#leaving injury, put on injury, and the players name. The method puts this data into the array that was passed as func_player\n",
    "def filter_pro_sports_transactions(line,func_player):\n",
    "    #/////////////////////////////////\n",
    "    # Title: Split a String and get First or Last element in Python\n",
    "    # Name: Borislav Hadzhiev\n",
    "    # Site Owner: Bobbyhadz\n",
    "    # Date: Feb. 19, 2023\n",
    "    # Code-Version: N/A\n",
    "    # Availability: https://bobbyhadz.com/blog/python-split-string-and-get-last-element\n",
    "    # Modified: Yes\n",
    "    func_dates = line.split(',')[0]\n",
    "    func_teams = line.split(',')[1]\n",
    "    func_leaving_injury = line.split(',')[2]\n",
    "    func_on_injury = line.split(',')[3]\n",
    "    func_injury = line.split(',')[4]\n",
    "    new_player = []\n",
    "    if len(func_on_injury) == 3 and len(func_leaving_injury.split(\" \")) > 3:\n",
    "            if len(line.split(',')[4]) != 10:\n",
    "                new_player = [func_leaving_injury.split(\" \")[2],func_leaving_injury.split(\" \")[3],func_dates,func_teams,func_injury,\"True\"]\n",
    "    elif len(func_leaving_injury) == 3 and len(func_on_injury.split(\" \")) > 3:\n",
    "            if len(line.split(',')[4]) != 10:\n",
    "                new_player = [func_on_injury.split(\" \")[2],func_on_injury.split(\" \")[3],func_dates,func_teams,func_injury,\"False\"]\n",
    "    if new_player:\n",
    "        func_player.append(new_player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "93e6660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates how long till the ending date for the season\n",
    "def calc_ending_dates_days(end_date, new_date):\n",
    "    if end_date:\n",
    "        end_date = end_date - new_date\n",
    "    else: end_date.days=0\n",
    "    return end_date.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "27b6f652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#searches which year the new_date is from if more recent than 2014, 9, 8. returns with the date in days\n",
    "def calc_recent_ending_dates(new_date):\n",
    "    if new_date >= datetime(2023,9,10):\n",
    "        end_date = datetime(2024,6,13)\n",
    "    elif new_date >= datetime(2022,9,7):\n",
    "        end_date = datetime(2023,6,13)\n",
    "    elif new_date >= datetime(2021,9,12):\n",
    "        end_date = datetime(2022,6,26)\n",
    "    elif new_date >= datetime(2021,1,13):\n",
    "        end_date = datetime(2021,7,7)\n",
    "    elif new_date >= datetime(2019,9,2):\n",
    "        end_date = datetime(2020,8,28)\n",
    "    elif new_date >= datetime(2018,9,3):\n",
    "        end_date = datetime(2019,6,12)\n",
    "    elif new_date >= datetime(2017,9,4):\n",
    "        end_date = datetime(2018,6,7)\n",
    "    elif new_date >= datetime(2016,9,12):\n",
    "        end_date = datetime(2017,6,11)\n",
    "    elif new_date >= datetime(2015,9,7):\n",
    "        end_date = datetime(2016,6,12)\n",
    "    elif new_date >= datetime(2014,9,8):\n",
    "        end_date = datetime(2015,6,15)\n",
    "    return calc_ending_dates_days(end_date,new_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "661b6c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#searches which year the new_date is from if later 2014, 9, 8 and before 2008, 6, 9. Returns with the date in days\n",
    "def calc_older_ending_dates(new_date):\n",
    "    if new_date >= datetime(2013,9,1):\n",
    "        end_date = datetime(2014,6,13)\n",
    "    elif new_date >= datetime(2013,1,19):\n",
    "        end_date = datetime(2013,6,24)\n",
    "    elif new_date >= datetime(2011,9,6):\n",
    "        end_date = datetime(2012,6,11)\n",
    "    elif new_date >= datetime(2010,9,7):\n",
    "        end_date = datetime(2011,6,15)\n",
    "    elif new_date >= datetime(2009,9,1):\n",
    "        end_date = datetime(2010,6,9)\n",
    "    elif new_date >= datetime(2008,9,4):\n",
    "        end_date = datetime(2009,6,12)\n",
    "    return calc_ending_dates_days(end_date,new_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "c4e30460",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calls the method required based on the date. Returns with the dates distance to the end date in days.\n",
    "def calc_ending_dates(new_date):\n",
    "    new_date = datetime.strptime(new_date,'%Y-%m-%d')\n",
    "    if new_date > datetime(2014,9,8):\n",
    "        end_date = calc_recent_ending_dates(new_date)\n",
    "    else:\n",
    "        end_date = calc_older_ending_dates(new_date)\n",
    "    return end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "7bdfb646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates which season the pass value is in. As long as the data is before 2014, 9, 8. returns with the season of new date.\n",
    "def calculate_recent_season_dates(new_date):\n",
    "    if new_date >= datetime(2023,9,10):\n",
    "        season =\"2023-24\" \n",
    "    elif datetime(2023,6,13) >= new_date >= datetime(2022,9,7):\n",
    "        season =\"2022-23\"\n",
    "    elif datetime(2022,6,26) >= new_date >= datetime(2021,9,12):\n",
    "        season = \"2021-22\"\n",
    "    elif datetime(2021,7,7) >= new_date >= datetime(2021,1,13):\n",
    "        season = \"2020-21\"\n",
    "    elif datetime(2020,8,28) >= new_date >= datetime(2019,9,2):\n",
    "        season = \"2019-20\"\n",
    "    elif datetime(2019,6,12) >= new_date >= datetime(2018,9,3):\n",
    "        season = \"2018-19\"\n",
    "    elif datetime(2018,6,7) >= new_date >= datetime(2017,9,4):\n",
    "        season = \"2017-18\"\n",
    "    elif datetime(2017,6,11) >= new_date >= datetime(2016,9,12):\n",
    "        season = \"2016-17\"\n",
    "    elif datetime(2016,6,12) >= new_date >= datetime(2015,9,7):\n",
    "        season = \"2015-16\"\n",
    "    elif datetime(2015,6,15) >= new_date >= datetime(2014,9,8):\n",
    "        season = \"2014-15\"\n",
    "    else: season=\"\"\n",
    "    return season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "db339696",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates which season the pass value is in. As long as the data is after 2014, 6, 13 and before 2002, 9, 9. returns with the season of new date.\n",
    "def calculate_older_dates(new_date):\n",
    "    if datetime(2014,6,13) >= new_date >= datetime(2013,9,1):\n",
    "            season = \"2013-14\"\n",
    "    elif datetime(2013,6,24) >= new_date >= datetime(2013,1,19):\n",
    "        season =\"2012-13\"        \n",
    "    elif datetime(2012,6,11) >= new_date >= datetime(2011,9,6):\n",
    "        season = \"2011-12\"\n",
    "    elif datetime(2011,6,15) >= new_date >= datetime(2010,9,7):\n",
    "        season = \"2010-11\"\n",
    "    elif datetime(2010,6,9) >= new_date >= datetime(2009,9,1):\n",
    "        season =\"2009-10\"\n",
    "    elif datetime(2009,6,12) >= new_date >= datetime(2008,9,4):\n",
    "        season =\"2008-09\"\n",
    "    elif datetime(2008,6,4) >= new_date >= datetime(2007,8,29):\n",
    "        season =\"2007-08\"\n",
    "    elif datetime(2007,6,6) >= new_date >= datetime(2006,9,4):\n",
    "        season = \"2006-07\"\n",
    "    elif datetime(2006,6,19) >= new_date >= datetime(2005,9,5):\n",
    "        season =\"2005-06\"\n",
    "    elif datetime(2004,6,7) >= new_date >= datetime(2003,9,8):\n",
    "        season = \"2003-04\"\n",
    "    elif datetime(2003,6,9) >= new_date >= datetime(2002,9,9):\n",
    "        season = \"2002-03\"\n",
    "    else: season = \"\"\n",
    "    return season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "cf7bd714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#runs through the list passed to it and sends the request to the appropriate method based on the date. Returns with the season of that date\n",
    "def calculate_season_dates(new_dates):\n",
    "    for i in new_dates:\n",
    "        clean_date = cleaning_results(i)\n",
    "        if len(new_dates) > 10:\n",
    "            new_date = datetime.strptime(clean_date,'%Y-%m-%d')\n",
    "        else:\n",
    "            new_date = datetime.strptime(new_dates,'%Y-%m-%d')\n",
    "        if new_date > datetime(2014,6,3):\n",
    "            season = calculate_recent_season_dates(new_date)\n",
    "        else:\n",
    "            season = calculate_older_dates(new_date)\n",
    "    return season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "3c0c656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This method is used to check whether an out for season injury occured and if it did occur save the date they started on the injury. \n",
    "#This also checks if an illness is part of the injured list.\n",
    "def calc_out_for_season_status(total_player_list,i,was_out_for_season,was_out_for_season_date,was_relinquished, was_relinquished_date):\n",
    "    if \"(out for season)\" in total_player_list[i][4]:\n",
    "        if was_out_for_season == True and was_out_for_season_date == calculate_season_dates(total_player_list[i][2]):\n",
    "            days = 0\n",
    "        else:  \n",
    "            days = calc_ending_dates(total_player_list[i][2])\n",
    "        was_out_for_season = True\n",
    "        was_out_for_season_date = calculate_season_dates(total_player_list[i][2])\n",
    "        was_relinquished = False\n",
    "    elif \"undisclosed\" in total_player_list[i][4] or \"COVID-19\" in total_player_list[i][4] or \"illness\" in total_player_list[i][4]:\n",
    "        days = 0\n",
    "        was_relinquished = False\n",
    "    else:\n",
    "        was_relinquished = True\n",
    "        was_relinquished_date = total_player_list[i][2]\n",
    "        days = 0\n",
    "    return days,was_relinquished,was_relinquished_date,was_out_for_season,was_out_for_season_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "85da68f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#goes over the list of total players and calculates how many days they were injured. \n",
    "def calculate_days(total_player_list):\n",
    "    was_relinquished = False\n",
    "    was_relinquished_date = \"\"\n",
    "    was_out_for_season = False\n",
    "    was_out_for_season_date = \"\"\n",
    "    days = 0\n",
    "    for i in range(len(total_player_list)):\n",
    "        if total_player_list[i][5] == \"True\":\n",
    "            total_player_list[i][2] = total_player_list[i][2].replace('[','')\n",
    "            if was_relinquished == True and calculate_season_dates(was_relinquished_date) == calculate_season_dates(total_player_list[i][2]):\n",
    "                new_date = datetime.strptime(total_player_list[i][2],'%Y-%m-%d') - datetime.strptime(was_relinquished_date,'%Y-%m-%d')\n",
    "                days = new_date.days\n",
    "            else:\n",
    "                days = 0\n",
    "            was_relinquished = False\n",
    "        elif total_player_list[i][5] == \"False\":\n",
    "            days, was_relinquished, was_relinquished_date,was_out_for_season,was_out_for_season_date = calc_out_for_season_status(total_player_list,i,was_out_for_season,was_out_for_season_date,was_relinquished, was_relinquished_date)\n",
    "        else:\n",
    "            days = 0\n",
    "        total_player_list[i].append(days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "f3a2ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lists all the injuries of a player in one season. Calculates the combined total of those injuries. Lastly it collects all the injury descriptions in a season\n",
    "def injury_calc(first_name,last_name,date,total_player_list):\n",
    "    injury_data = []\n",
    "    injury_desc = []\n",
    "    cumalitive_injury = 0\n",
    "    for i in range(len(total_player_list)):\n",
    "        if total_player_list[i][0] == first_name and total_player_list[i][1] == last_name and date == calculate_season_dates(total_player_list[i][2]) and int(total_player_list[i][6]) > 0:\n",
    "            if \"out for season\" in total_player_list[i][4]:\n",
    "                injury_desc.append(total_player_list[i][4])\n",
    "            else:\n",
    "                injury_desc.append(total_player_list[i-1][4])\n",
    "            if injury_data[0] == 0:\n",
    "                injury_data.remove(0)\n",
    "            injury_data.append(total_player_list[i][6])\n",
    "            cumalitive_injury += total_player_list[i][6]\n",
    "        elif not injury_data:\n",
    "            injury_data.append(0)\n",
    "    return str(injury_data),str(cumalitive_injury),str(injury_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "d2f27e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts the list passed to it to csv format. Adds those to the csv that is also passed to it as file\n",
    "def to_csv(array,file):\n",
    "    #/////////////////////////////////////////\n",
    "# Title: pandas.DataFrame.to_csv\n",
    "# Name: N/A\n",
    "# Site Owner: Pandas\n",
    "# Date: N/A\n",
    "# Code-Version: 2.1.3\n",
    "# Availability: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html\n",
    "# Modified: Yes\n",
    "    df = pd.DataFrame(array,columns=[\"Player First Name\",\"Player Last Name\", \"Position\", \"Season\",\"Age\",\"Team\",\"League\",\n",
    "                  \"Games Played\",\"Goals\",\"Assists\",\"Points\",\"+/-\",\"Penalties in Minutes\",\"Even Strength Goals\",\"Power Play Goals\",\"Short Handed Goals\",\n",
    "                  \"Game-Winning Goals\",\"Even Strength Assists\",\"Power Play Assists\",\"Short-Handed Assists\",\"Shots On Goals\",\"Shooting Percentage\",\"Total Shoot Assists\",\n",
    "                  \"Time on Minutes\",\"Average Time on Ice\",\"Faceoff Wins\",\"Faceoff Losses\",\"Faceoff Percentage\",\"Blocks\",\"Hits\",\"Takeaways\",\"Giveaways\",\"Awards\",\"Injury Time\",\"Total Time Out This Year\",\"Injury Description\"])\n",
    "    df.to_csv(file, encoding = 'utf-8-sig' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "4a7669fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts data from the yearly dataset to a list and returns it with the same amount of columns to match the other datasets. \n",
    "def convert_array(no_dup_list,season):\n",
    "    stats_array = []\n",
    "    for e in no_dup_list:\n",
    "        if e:\n",
    "            stats_array.append([e[0].split(' ')[0],e[0].split(' ')[1],e[3],season,e[1],e[2],\n",
    "                                \"NHL\",e[4],e[5],e[6],e[7],e[8],e[9],e[11],e[12],e[13],e[14],\n",
    "                                e[15],e[16],e[17],e[18],e[19],\"\",e[20],e[21],e[24],e[25],\n",
    "                                e[26],e[22],e[23],\"\",\"\",\"\",0,0,\"\"])\n",
    "    return stats_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "74071de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In trades a players data gets their data repeated as there is a total, the first team stats, the second teams stats and so on. \n",
    "#This removes the repeated values from the list and returns it\n",
    "def check_duplicates_trade(current_array):\n",
    "    previous_season = \"\"\n",
    "    previous_first_name = \"\"\n",
    "    previous_last_name = \"\"\n",
    "    previously_traded = False\n",
    "    new_array =[]\n",
    "    append_bool = False\n",
    "\n",
    "    for e in current_array:\n",
    "\n",
    "        if previously_traded == True:\n",
    "            if e[3] != previous_season or e[0] != previous_first_name or e[1] != previous_last_name:\n",
    "                append_bool =True\n",
    "            else:\n",
    "                append_bool=False\n",
    "        else:\n",
    "            append_bool=True\n",
    "            previously_traded = False\n",
    "        if e[5] == \"TOT\":\n",
    "            previously_traded = True\n",
    "        \n",
    "        if append_bool:\n",
    "            new_array.append(e)\n",
    "        previous_season = e[3]\n",
    "        previous_first_name = e[0]\n",
    "        previous_last_name = e[1]\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "4e600d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a new array without any injured player data in it. This only adds to this list when there is no match between the player in the two datasets\n",
    "def create_control_group(yearly_data,injury_data):\n",
    "    function_array = []\n",
    "    for i in yearly_data:\n",
    "        for j in injury_data:\n",
    "            if i[0] == j[0] and i[1] == j[1]:\n",
    "                break\n",
    "        else:\n",
    "            function_array.append(i)\n",
    "\n",
    "    return function_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "1d008548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#is passed a year value this then gets a list of all players for that hockey season.\n",
    "def get_hockey_year_data(year):\n",
    "    year_skaters = \"20\" + year[5:7]\n",
    "    yearlyURL =  \"https://www.hockey-reference.com/leagues/NHL_\" + year_skaters + \"_skaters.html\"\n",
    "    yearly_dataset = []\n",
    "    stats_array = []\n",
    "    response =requests.get(yearlyURL.format())\n",
    "    soup=BeautifulSoup(response.content, HTML_PARSER)\n",
    "    table = soup.find('table', id=\"stats\")\n",
    "    for i, row in enumerate(table.find_all('tr')):\n",
    "        if i > 1:\n",
    "            yearly_dataset.append([el.text.strip() for el in row.find_all('td')])\n",
    "\n",
    "    stats_array = convert_array(yearly_dataset,year)\n",
    "    return stats_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "a14f8306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the data collector for the initial injury dataset\n",
    "def scrap_dataset():\n",
    "    #/////////////////////////////////\n",
    "# Title: How to scrape tables with BeautifulSoup?\n",
    "# Name: Dimitrije Stamenic\n",
    "# Site Owner: ScrapFly\n",
    "# Date: OCt. 24, 2022\n",
    "# Code-Version: N/A\n",
    "# Availability: https://scrapfly.io/blog/how-to-scrape-tables-with-beautifulsoup/\n",
    "# Modified: Yes\n",
    "#Creates initial dataset by scrapping the from Pro-Sports Transactions\n",
    "    page = 0\n",
    "    response =requests.get(url.format(START_DATE,END_DATE,page))\n",
    "    \n",
    "    soup=BeautifulSoup(response.content, HTML_PARSER)\n",
    "    table = soup.find('table')\n",
    "    while (len(table.find_all('tr')) > 1):\n",
    "        page +=25\n",
    "        for i, row in enumerate(table.find_all('tr')):\n",
    "            if i > 0:\n",
    "                rows.append([el.text.strip() for el in row.find_all('td')])\n",
    "        response =requests.get(url.format(START_DATE,END_DATE,page))\n",
    "        soup=BeautifulSoup(response.content, HTML_PARSER)\n",
    "        table = soup.find('table')\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "106cee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#is given a list of hockey player rows. This then check if that same first and last name are already in the dataset\n",
    "def no_duplicates_intial_list(rows):\n",
    "    rows_without_duplicates = []\n",
    "    a = set()\n",
    "    for i in range(len(rows)):\n",
    "        if rows[i][2]:\n",
    "            inner_tuple = tuple(rows[i][2])\n",
    "        elif rows[i][3]:\n",
    "            inner_tuple = tuple(rows[i][3])\n",
    "        if inner_tuple not in a:\n",
    "            rows_without_duplicates.append(rows[i])\n",
    "            a.add(inner_tuple)\n",
    "    return rows_without_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "0bea973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search specific players from the first dataset and collects all of their past or current injuriess and returns a list of them.\n",
    "def player_injury_history(initial_player_list):\n",
    "    injury_dataset = []\n",
    "    for i in initial_player_list:\n",
    "        page=0\n",
    "        injuryURL =  \"https://www.prosportstransactions.com/hockey/Search/SearchResults.php?Player=\" + i[0] + \"+\" + i[1] + \"&Team=&BeginDate=&EndDate=&ILChkBx=yes&submit=Search&start={}\"\n",
    "        print(injuryURL)\n",
    "        response =requests.get(injuryURL.format(page))\n",
    "        soup=BeautifulSoup(response.content, HTML_PARSER)\n",
    "        table = soup.find('table')\n",
    "        while (len(table.find_all('tr')) > 1):\n",
    "            page +=25\n",
    "            for i, row in enumerate(table.find_all('tr')):\n",
    "                if i > 0:\n",
    "                    injury_dataset.append([el.text.strip() for el in row.find_all('td')])\n",
    "            response =requests.get(injuryURL.format(page))\n",
    "            soup=BeautifulSoup(response.content, HTML_PARSER)\n",
    "            table = soup.find('table')\n",
    "    return injury_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "c710e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Goes through and filters data from the injury dataset, and cleans the total player list\n",
    "def player_injury_cleaning(total_player_list,injury_dataset):\n",
    "    for i in range(len(injury_dataset)):\n",
    "        filter_pro_sports_transactions(str(injury_dataset[i]),total_player_list)\n",
    "            \n",
    "    for i in range(len(total_player_list)):\n",
    "        for e in range(len(total_player_list[i])):\n",
    "            total_player_list[i][e] = cleaning_results(total_player_list[i][e])\n",
    "    return total_player_list,injury_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "a5863659",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generates the url for hockey reference players\n",
    "def create_url(data):\n",
    "    last_one = data[1][0].lower()\n",
    "    first_two = data[0][0].lower() + data[0][1].lower()\n",
    "    last_five = data[1][0:5].lower()\n",
    "    page_numb = 1\n",
    "    time.sleep(2)\n",
    "    return \"https://www.hockey-reference.com/players/\" + last_one + \"/\" + last_five + first_two + \"0\" + str(page_numb) + \".html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "43c5c5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seaches a players page for their player position\n",
    "def find_player_position(soup):\n",
    "    strong = soup.find('strong',string=\"Position\")\n",
    "    if strong:\n",
    "        new_strong = str(strong.next_sibling.text.split(\" \")[1])\n",
    "        new_strong = new_strong[0]\n",
    "    if new_strong == 'R':\n",
    "        new_strong = 'RW'\n",
    "    elif new_strong == 'L':\n",
    "        new_strong = 'LW'\n",
    "    new_strong = [new_strong]\n",
    "    return new_strong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "b2bdd21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_hockey_reference_to_list(final_rows,cols,data):\n",
    "    if (len(final_rows)>0) and len(final_rows[0])==31:\n",
    "        for e in final_rows:\n",
    "            if e[2] != \"\":\n",
    "                t1,t2,t3 = injury_calc(data[0],data[1], e[1],total_player_list)\n",
    "                cols.append([data[0], data[1], e[0],e[1],e[2],e[3],e[4],e[5],e[6],e[7],e[8],e[9],e[10],e[11],e[12],e[13],e[14],e[15],\n",
    "                e[16],e[17],e[18],e[19],e[20],e[21],e[22],e[23],e[24],e[25],e[26],e[27],e[28],e[29],e[30],str(t1)[1:-1],t2,str(t3)[1:-1]])\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "cda80454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def hockey_reference_data_collection(initial_player_list,final_rows,cols):\n",
    "    for data in initial_player_list:\n",
    "        url = create_url(data)\n",
    "        print(url)\n",
    "        table = None\n",
    "        response =requests.get(url.format())\n",
    "        soup=BeautifulSoup(response.content, HTML_PARSER)\n",
    "        new_strong = find_player_position(soup)\n",
    "        table = soup.find('table', id=\"stats_basic_plus_nhl\")\n",
    "        if table is not None:\n",
    "            for i, row in enumerate(table.find_all('tr')):\n",
    "                if i > 1:\n",
    "                    years = [el.text.strip() for el in row.find_all('th')]\n",
    "                    player = [el.text.strip() for el in row.find_all('td')]\n",
    "                    final_rows.append(new_strong + years + player)\n",
    "        final_columns = append_hockey_reference_to_list(final_rows,cols,data)\n",
    "        #print(append_hockey_reference_to_list(final_rows,cols,data)[0])\n",
    "        final_rows = []\n",
    "    return final_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d94b16e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fc8e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "dc6f117d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.prosportstransactions.com/hockey/Search/SearchResults.php?Player=Matt+Nieto&Team=&BeginDate=&EndDate=&ILChkBx=yes&submit=Search&start={}\n",
      "https://www.prosportstransactions.com/hockey/Search/SearchResults.php?Player=Travis+Hamonic&Team=&BeginDate=&EndDate=&ILChkBx=yes&submit=Search&start={}\n",
      "https://www.prosportstransactions.com/hockey/Search/SearchResults.php?Player=Gabriel+Bourque&Team=&BeginDate=&EndDate=&ILChkBx=yes&submit=Search&start={}\n",
      "https://www.prosportstransactions.com/hockey/Search/SearchResults.php?Player=Jared+McCann&Team=&BeginDate=&EndDate=&ILChkBx=yes&submit=Search&start={}\n",
      "https://www.prosportstransactions.com/hockey/Search/SearchResults.php?Player=Roberto+Luongo&Team=&BeginDate=&EndDate=&ILChkBx=yes&submit=Search&start={}\n",
      "https://www.prosportstransactions.com/hockey/Search/SearchResults.php?Player=Anton+Lindholm&Team=&BeginDate=&EndDate=&ILChkBx=yes&submit=Search&start={}\n",
      "https://www.prosportstransactions.com/hockey/Search/SearchResults.php?Player=Cam+Atkinson&Team=&BeginDate=&EndDate=&ILChkBx=yes&submit=Search&start={}\n",
      "https://www.prosportstransactions.com/hockey/Search/SearchResults.php?Player=Matt+Calvert&Team=&BeginDate=&EndDate=&ILChkBx=yes&submit=Search&start={}\n",
      "https://www.prosportstransactions.com/hockey/Search/SearchResults.php?Player=Brett+Ritchie&Team=&BeginDate=&EndDate=&ILChkBx=yes&submit=Search&start={}\n",
      "https://www.prosportstransactions.com/hockey/Search/SearchResults.php?Player=Gabriel+Carlsson&Team=&BeginDate=&EndDate=&ILChkBx=yes&submit=Search&start={}\n",
      "https://www.hockey-reference.com/players/n/nietoma01.html\n",
      "https://www.hockey-reference.com/players/h/hamontr01.html\n",
      "https://www.hockey-reference.com/players/b/bourqga01.html\n",
      "https://www.hockey-reference.com/players/m/mccanja01.html\n",
      "https://www.hockey-reference.com/players/l/luongro01.html\n",
      "https://www.hockey-reference.com/players/l/lindhan01.html\n",
      "https://www.hockey-reference.com/players/a/atkinca01.html\n",
      "https://www.hockey-reference.com/players/c/calvema01.html\n",
      "https://www.hockey-reference.com/players/r/ritchbr01.html\n",
      "https://www.hockey-reference.com/players/c/carlsga01.html\n"
     ]
    }
   ],
   "source": [
    "rows = scrap_dataset()\n",
    "rows_without_duplicates = no_duplicates_intial_list(rows)\n",
    "\n",
    "file1.writelines(\"% s\\n\" % data for data in rows_without_duplicates)\n",
    "file1.close()\n",
    "file1 = open(\"hockeydata.txt\", 'r')\n",
    "for line in file1:\n",
    "    totalFile.append(line)\n",
    "    filter_pro_sports_transactions(line,initial_player_list)\n",
    "file1.close()  \n",
    "\n",
    "for iter in range(len(initial_player_list)):\n",
    "    for numb in range(len(initial_player_list[iter])):\n",
    "        initial_player_list[iter][numb] = cleaning_results(initial_player_list[iter][numb])\n",
    "\n",
    "injury_dataset = player_injury_history(initial_player_list)\n",
    "\n",
    "total_player_list,injury_dataset = player_injury_cleaning(total_player_list,injury_dataset)\n",
    "calculate_days(total_player_list)\n",
    "\n",
    "cols = hockey_reference_data_collection(initial_player_list,final_row,cols)\n",
    "hockey_year = \"2021-22\"\n",
    "stats_array = get_hockey_year_data(hockey_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "844d7352",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rows_above_zero = []\n",
    "rows_above_zero=[]\n",
    "year_data_above_zero = []\n",
    "new_player_data = []\n",
    "for e in cols:\n",
    "    if int(e[34]) > 0:\n",
    "        rows_above_zero.append(e)\n",
    "        if e[3] == hockey_year:\n",
    "            year_data_above_zero.append(e)\n",
    "        else:\n",
    "            new_rows_above_zero.append(e)\n",
    "    if e[3] != hockey_year:\n",
    "        new_player_data.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "dfbe379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_array = check_duplicates_trade(stats_array)\n",
    "control_group = []\n",
    "control_group = create_control_group(stats_array,year_data_above_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "802e44ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "all_players = []\n",
    "no_dup_players = []\n",
    "new_player_data =check_duplicates_trade(new_player_data)\n",
    "\n",
    "new_rows_above_zero = check_duplicates_trade(new_rows_above_zero)\n",
    "year_data_above_zero = check_duplicates_trade(year_data_above_zero)\n",
    "\n",
    "to_csv(new_player_data,\"player_data.csv\")\n",
    "to_csv(new_rows_above_zero,\"player_injuries.csv\")\n",
    "to_csv(control_group,\"yearly_data.csv\")\n",
    "to_csv(year_data_above_zero,\"yearly_data_above_zero.csv\")\n",
    "print(\"finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
