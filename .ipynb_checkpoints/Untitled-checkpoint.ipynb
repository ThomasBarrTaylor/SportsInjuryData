{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ee2881-d4ec-4fe8-a399-c74dbc8ae5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c0227d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/////////////////////////////////\n",
    "# Title: Reading and Writing to text files in Python\n",
    "# Name: N/A\n",
    "# Site Owner: Geeks for Geeks\n",
    "# Date: August 28, 2023\n",
    "# Code-Version: N/A\n",
    "# Availability: https://www.geeksforgeeks.org/reading-writing-text-files-python/\n",
    "# Modified: Yes\n",
    "file1 = open(\"hockeydata.txt\", 'w')\n",
    "START_DATE=\"2017-11-04\"\n",
    "END_DATE=\"2017-11-08\"\n",
    "page=0\n",
    "rows=[]\n",
    "totalFile = []\n",
    "final_rows=[]\n",
    "HTML_PARSER = \"html.parser\"\n",
    "#/////////////////////////////////\n",
    "# Title: How to scrape tables with BeautifulSoup?\n",
    "# Name: Dimitrije Stamenic\n",
    "# Site Owner: ScrapFly\n",
    "# Date: OCt. 24, 2022\n",
    "# Code-Version: N/A\n",
    "# Availability: https://scrapfly.io/blog/how-to-scrape-tables-with-beautifulsoup/\n",
    "# Modified: Yes\n",
    "url = \"https://www.prosportstransactions.com/hockey/Search/SearchResults.php?Player=&Team=&BeginDate={}&EndDate={}&ILChkBx=yes&submit=Search&start={}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4e820ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_results(item_to_clean):\n",
    "    item_to_clean = item_to_clean.replace(\"'\",\"\")\n",
    "    item_to_clean = item_to_clean.replace('\"','')\n",
    "    item_to_clean = item_to_clean.replace('[','')\n",
    "    item_to_clean = item_to_clean.replace(\"]\",\"\")\n",
    "    return item_to_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ed597ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pro_sports_transactions(line,func_player):\n",
    "    \n",
    "    func_dates = line.split(',')[0]\n",
    "    func_teams = line.split(',')[1]\n",
    "    func_leaving_injury = line.split(',')[2]\n",
    "    func_on_injury = line.split(',')[3]\n",
    "    func_injury = line.split(',')[4]\n",
    "    new_player = []\n",
    "    if len(func_on_injury) == 3 and len(func_leaving_injury.split(\" \")) > 3:\n",
    "            if len(line.split(',')[4]) != 10:\n",
    "                new_player = [func_leaving_injury.split(\" \")[2],func_leaving_injury.split(\" \")[3],func_dates,func_teams,func_injury,\"True\"]\n",
    "    elif len(func_leaving_injury) == 3 and len(func_on_injury.split(\" \")) > 3:\n",
    "            if len(line.split(',')[4]) != 10:\n",
    "                new_player = [func_on_injury.split(\" \")[2],func_on_injury.split(\" \")[3],func_dates,func_teams,func_injury,\"False\"]\n",
    "    if new_player:\n",
    "        func_player.append(new_player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f27635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ending_dates(new_date):\n",
    "    end_date =\"\"\n",
    "    new_date = datetime.strptime(new_date,'%Y-%m-%d')\n",
    "    if new_date >= datetime(2023,9,10):\n",
    "        end_date = datetime(2024,6,13)\n",
    "    elif new_date >= datetime(2022,9,7):\n",
    "        end_date = datetime(2023,6,13)\n",
    "    elif new_date >= datetime(2021,9,12):\n",
    "        end_date = datetime(2022,6,26)\n",
    "    elif new_date >= datetime(2021,1,13):\n",
    "        end_date = datetime(2021,7,7)\n",
    "    elif new_date >= datetime(2019,9,2):\n",
    "        end_date = datetime(2020,8,28)\n",
    "    elif new_date >= datetime(2018,9,3):\n",
    "        end_date = datetime(2019,6,12)\n",
    "    elif new_date >= datetime(2017,9,4):\n",
    "        end_date = datetime(2018,6,7)\n",
    "    elif new_date >= datetime(2016,9,12):\n",
    "        end_date = datetime(2017,6,11)\n",
    "    elif new_date >= datetime(2015,9,7):\n",
    "        end_date = datetime(2016,6,12)\n",
    "    elif new_date >= datetime(2014,9,8):\n",
    "        end_date = datetime(2015,6,15)\n",
    "    elif new_date >= datetime(2013,9,1):\n",
    "        end_date = datetime(2014,6,13)\n",
    "    elif new_date >= datetime(2013,1,19):\n",
    "        end_date = datetime(2013,6,24)\n",
    "    elif new_date >= datetime(2011,9,6):\n",
    "        end_date = datetime(2012,6,11)\n",
    "    elif new_date >= datetime(2010,9,7):\n",
    "        end_date = datetime(2011,6,15)\n",
    "    elif new_date >= datetime(2009,9,1):\n",
    "        end_date = datetime(2010,6,9)\n",
    "    elif new_date >= datetime(2008,9,4):\n",
    "        end_date = datetime(2009,6,12)\n",
    "    if end_date:\n",
    "        end_date = end_date - new_date\n",
    "        return end_date.days\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bdfb646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_season_dates(new_dates):\n",
    "    season = \"\"\n",
    "    for i in new_dates:\n",
    "        if len(new_dates) > 10:\n",
    "            new_date = datetime.strptime(i,'%Y-%m-%d')\n",
    "        else:\n",
    "            new_date = datetime.strptime(new_dates,'%Y-%m-%d')\n",
    "\n",
    "        if new_date >= datetime(2023,9,10):\n",
    "            season =\"2023-24\" \n",
    "        elif datetime(2023,6,13) >= new_date >= datetime(2022,9,7):\n",
    "            season =\"2022-23\"\n",
    "        elif datetime(2022,6,26) >= new_date >= datetime(2021,9,12):\n",
    "            season = \"2021-22\"\n",
    "        elif datetime(2021,7,7) >= new_date >= datetime(2021,1,13):\n",
    "            season = \"2020-21\"\n",
    "        elif datetime(2020,8,28) >= new_date >= datetime(2019,9,2):\n",
    "            season = \"2019-20\"\n",
    "        elif datetime(2019,6,12) >= new_date >= datetime(2018,9,3):\n",
    "            season = \"2018-19\"\n",
    "        elif datetime(2018,6,7) >= new_date >= datetime(2017,9,4):\n",
    "            season = \"2017-18\"\n",
    "        elif datetime(2017,6,11) >= new_date >= datetime(2016,9,12):\n",
    "            season = \"2016-17\"\n",
    "        elif datetime(2016,6,12) >= new_date >= datetime(2015,9,7):\n",
    "            season = \"2015-16\"\n",
    "        elif datetime(2015,6,15) >= new_date >= datetime(2014,9,8):\n",
    "            season = \"2014-15\"\n",
    "        elif datetime(2014,6,13) >= new_date >= datetime(2013,9,1):\n",
    "            season = \"2013-14\"\n",
    "        elif datetime(2013,6,24) >= new_date >= datetime(2013,1,19):\n",
    "            season =\"2012-13\"\n",
    "        elif datetime(2012,6,11) >= new_date >= datetime(2011,9,6):\n",
    "            season = \"2011-12\"\n",
    "        elif datetime(2011,6,15) >= new_date >= datetime(2010,9,7):\n",
    "            season = \"2010-11\"\n",
    "        elif datetime(2010,6,9) >= new_date >= datetime(2009,9,1):\n",
    "            season =\"2009-10\"\n",
    "        elif datetime(2009,6,12) >= new_date >= datetime(2008,9,4):\n",
    "            season =\"2008-09\"\n",
    "        elif datetime(2008,6,4) >= new_date >= datetime(2007,8,29):\n",
    "            season =\"2007-08\"\n",
    "        elif datetime(2007,6,6) >= new_date >= datetime(2006,9,4):\n",
    "            season = \"2006-07\"\n",
    "        elif datetime(2006,6,19) >= new_date >= datetime(2005,9,5):\n",
    "            season =\"2005-06\"\n",
    "        elif datetime(2004,6,7) >= new_date >= datetime(2003,9,8):\n",
    "            season = \"2003-04\"\n",
    "        elif datetime(2003,6,9) >= new_date >= datetime(2002,9,9):\n",
    "            season = \"2002-03\"\n",
    "        else:\n",
    "            season = \"\"\n",
    "    return season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85da68f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_days(total_player_list):\n",
    "    was_relinquished = False\n",
    "    was_out_for_season = False\n",
    "    was_out_for_season_date = \"\"\n",
    "    days = 0\n",
    "    for i in range(len(total_player_list)):\n",
    "        if total_player_list[i][5] == \"True\":\n",
    "            if was_relinquished == True and calculate_season_dates(was_relinquished_date) == calculate_season_dates(total_player_list[i][2]):\n",
    "                new_date = datetime.strptime(total_player_list[i][2],'%Y-%m-%d') - datetime.strptime(was_relinquished_date,'%Y-%m-%d')\n",
    "\n",
    "                days = new_date.days\n",
    "            else:\n",
    "                days = 0\n",
    "            was_relinquished = False\n",
    "        elif total_player_list[i][5] == \"False\":\n",
    "            if \"(out for season)\" in total_player_list[i][4]:\n",
    "                if was_out_for_season == True and was_out_for_season_date == calculate_season_dates(total_player_list[i][2]):\n",
    "                    days = 0\n",
    "                else:  \n",
    "                    days = calc_ending_dates(total_player_list[i][2])\n",
    "                was_out_for_season = True\n",
    "                was_out_for_season_date = calculate_season_dates(total_player_list[i][2])\n",
    "                was_relinquished = False\n",
    "            elif \"undisclosed\" in total_player_list[i][4] or \"COVID-19\" in total_player_list[i][4] or \"illness\" in total_player_list[i][4]:\n",
    "                days = 0\n",
    "                was_relinquished = False\n",
    "            else:\n",
    "                was_relinquished = True\n",
    "                was_relinquished_date = total_player_list[i][2]\n",
    "                days = 0\n",
    "        else:\n",
    "            days = 0\n",
    "        total_player_list[i].append(days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3a2ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def injury_calc(first_name,last_name,date,total_player_list):\n",
    "    injury_data = []\n",
    "    injury_desc = []\n",
    "    cumalitive_injury = 0\n",
    "    for i in range(len(total_player_list)):\n",
    "        if total_player_list[i][0] == first_name and total_player_list[i][1] == last_name and date == calculate_season_dates(total_player_list[i][2]) and int(total_player_list[i][6]) > 0:\n",
    "            if \"out for season\" in total_player_list[i][4]:\n",
    "                injury_desc.append(total_player_list[i][4])\n",
    "            else:\n",
    "                injury_desc.append(total_player_list[i-1][4])\n",
    "            if injury_data[0] == 0:\n",
    "                injury_data.remove(0)\n",
    "            injury_data.append(total_player_list[i][6])\n",
    "            cumalitive_injury += total_player_list[i][6]\n",
    "        elif not injury_data:\n",
    "            injury_data.append(0)\n",
    "    return str(injury_data),str(cumalitive_injury),str(injury_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2f27e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv(array,file):\n",
    "    df = pd.DataFrame(array,columns=[\"Player First Name\",\"Player Last Name\", \"Position\", \"Season\",\"Age\",\"Team\",\"League\",\n",
    "                  \"Games Played\",\"Goals\",\"Assists\",\"Points\",\"+/-\",\"Penalties in Minutes\",\"Even Strength Goals\",\"Power Play Goals\",\"Short Handed Goals\",\n",
    "                  \"Game-Winning Goals\",\"Even Strength Assists\",\"Power Play Assists\",\"Short-Handed Assists\",\"Shots On Goals\",\"Shooting Percentage\",\"Total Shoot Assists\",\n",
    "                  \"Time on Minutes\",\"Average Time on Ice\",\"Faceoff Wins\",\"Faceoff Losses\",\"Faceoff Percentage\",\"Blocks\",\"Hits\",\"Takeaways\",\"Giveaways\",\"Awards\",\"Injury Time\",\"Total Time Out This Year\",\"Injury Description\"])\n",
    "    df.to_csv(file, encoding = 'utf-8-sig' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a7669fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_array(no_dup_list,season):\n",
    "    stats_array = []\n",
    "    for e in no_dup_list:\n",
    "        if e:\n",
    "            stats_array.append([e[0].split(' ')[0],e[0].split(' ')[1],e[3],season,e[1],e[2],\n",
    "                                \"NHL\",e[4],e[5],e[6],e[7],e[8],e[9],e[11],e[12],e[13],e[14],\n",
    "                                e[15],e[16],e[17],e[18],e[19],\"\",e[20],e[21],e[24],e[25],\n",
    "                                e[26],e[22],e[23],\"\",\"\",\"\",\"\",\"\",\"\"])\n",
    "    return stats_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74071de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates(current_array):\n",
    "    previous_season = \"\"\n",
    "    previous_first_name = \"\"\n",
    "    previous_last_name = \"\"\n",
    "    previously_traded = False\n",
    "    new_array =[]\n",
    "    append_bool = False\n",
    "\n",
    "    for e in current_array:\n",
    "\n",
    "        if previously_traded == True:\n",
    "            if e[3] != previous_season or e[0] != previous_first_name or e[1] != previous_last_name:\n",
    "                append_bool =True\n",
    "            else:\n",
    "                append_bool=False\n",
    "        else:\n",
    "            append_bool=True\n",
    "            previously_traded = False\n",
    "        if e[5] == \"TOT\":\n",
    "            previously_traded = True\n",
    "        \n",
    "        if append_bool:\n",
    "            new_array.append(e)\n",
    "        previous_season = e[3]\n",
    "        previous_first_name = e[0]\n",
    "        previous_last_name = e[1]\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e600d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_control_group(yearly_data,injury_data):\n",
    "    function_array = []\n",
    "    for i in yearly_data:\n",
    "        for j in injury_data:\n",
    "            if i[0] == j[0] and i[1] == j[1]:\n",
    "                break\n",
    "        else:\n",
    "            function_array.append(i)\n",
    "\n",
    "    return function_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8578962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page: 25\n"
     ]
    }
   ],
   "source": [
    "initial_player_list=[]\n",
    "response =requests.get(url.format(START_DATE,END_DATE,page))\n",
    "soup=BeautifulSoup(response.content, HTML_PARSER)\n",
    "table = soup.find('table')\n",
    "while (len(table.find_all('tr')) > 1):\n",
    "    page +=25\n",
    "    print(\"page: \" + str(page))\n",
    "    for i, row in enumerate(table.find_all('tr')):\n",
    "        if i > 0:\n",
    "            rows.append([el.text.strip() for el in row.find_all('td')])\n",
    "    response =requests.get(url.format(START_DATE,END_DATE,page))\n",
    "    soup=BeautifulSoup(response.content, HTML_PARSER)\n",
    "    table = soup.find('table')\n",
    "rows_without_duplicates = []\n",
    "a = set()\n",
    "for i in range(len(rows)):\n",
    "    if rows[i][2]:\n",
    "        inner_tuple = tuple(rows[i][2])\n",
    "    elif rows[i][3]:\n",
    "        inner_tuple = tuple(rows[i][3])\n",
    "    if inner_tuple not in a:\n",
    "        rows_without_duplicates.append(rows[i])\n",
    "        a.add(inner_tuple)\n",
    "file1.writelines(\"% s\\n\" % data for data in rows_without_duplicates)\n",
    "file1.close()\n",
    "file1 = open(\"hockeydata.txt\", 'r')\n",
    "for line in file1:\n",
    "    #/////////////////////////////////\n",
    "    # Title: Split a String and get First or Last element in Python\n",
    "    # Name: Borislav Hadzhiev\n",
    "    # Site Owner: Bobbyhadz\n",
    "    # Date: Feb. 19, 2023\n",
    "    # Code-Version: N/A\n",
    "    # Availability: https://bobbyhadz.com/blog/python-split-string-and-get-last-element\n",
    "    # Modified: Yes\n",
    "    totalFile.append(line)\n",
    "    filter_pro_sports_transactions(line,initial_player_list)\n",
    "file1.close()  \n",
    "#/////////////////////////////////\n",
    "# Title: How to Remove Quotes from Strings in Python\n",
    "# Name: Dimitrije Stamenic\n",
    "# Site Owner: StackAbuse\n",
    "# Date: June 1, 2023\n",
    "# Code-Version: N/A\n",
    "# Availability: https://stackabuse.com/how-to-remove-quotes-from-string-in-python/\n",
    "# Modified: Yes\n",
    "for iter in range(len(initial_player_list)):\n",
    "    for numb in range(len(initial_player_list[iter])):\n",
    "        initial_player_list[iter][numb] = cleaning_results(initial_player_list[iter][numb])\n",
    "newIterator = 0\n",
    "name = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3fc8e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_above_zero = []\n",
    "year_data_above_zero = []\n",
    "total_player = []\n",
    "total_player_list = []\n",
    "for i in initial_player_list:\n",
    "    player_pages = 0\n",
    "    injury_iter = 0\n",
    "    injury_dataset = []\n",
    "    injuryURL =  \"https://www.prosportstransactions.com/hockey/Search/SearchResults.php?Player=\" + i[0] + \"+\" + i[1] + \"&Team=&BeginDate=&EndDate=&ILChkBx=yes&submit=Search&start={}\"\n",
    "    response =requests.get(injuryURL.format(player_pages))\n",
    "    soup=BeautifulSoup(response.content, HTML_PARSER)\n",
    "    table = soup.find('table')\n",
    "    if table:\n",
    "        for i, row in enumerate(table.find_all('tr')):\n",
    "            if i != 0:\n",
    "                injury_dataset.append([el.text.strip() for el in row.find_all('td')])\n",
    "        if len(table.find_all('tr')) == 26:\n",
    "            player_pages += 25\n",
    "            response =requests.get(injuryURL.format(player_pages))\n",
    "            soup=BeautifulSoup(response.content, HTML_PARSER)\n",
    "            table = soup.find('table')\n",
    "            for i, row in enumerate(table.find_all('tr')):\n",
    "                if i != 0:\n",
    "                    injury_dataset.append([el.text.strip() for el in row.find_all('td')])\n",
    "           \n",
    "    for i in range(len(injury_dataset)):\n",
    "        filter_pro_sports_transactions(str(injury_dataset[i]),total_player_list)\n",
    "        \n",
    "    for i in range(len(total_player_list)):\n",
    "        for e in range(len(total_player_list[i])):\n",
    "            total_player_list[i][e] = cleaning_results(total_player_list[i][e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc6f117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_days(total_player_list)\n",
    "    #total_player_list[e].append(injury_calc(total_player_list[e][0],total_player_list[e][1],total_player_list[e][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cc57080-1c81-42c3-84be-fe6a94449cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.hockey-reference.com/players/n/nietoma01.html\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'final_rows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m             years \u001b[38;5;241m=\u001b[39m [el\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m row\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mth\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m     34\u001b[0m             player \u001b[38;5;241m=\u001b[39m [el\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m row\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtd\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m---> 35\u001b[0m             \u001b[43mfinal_rows\u001b[49m\u001b[38;5;241m.\u001b[39mappend(new_strong \u001b[38;5;241m+\u001b[39m years \u001b[38;5;241m+\u001b[39m player)\n\u001b[0;32m     36\u001b[0m l \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     37\u001b[0m repeat_player \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_rows' is not defined"
     ]
    }
   ],
   "source": [
    "cols = []\n",
    "new_rows = []\n",
    "year_data = []\n",
    "for data in initial_player_list:\n",
    "    last_one = data[1][0].lower()\n",
    "    first_two = data[0][0].lower() + data[0][1].lower()\n",
    "    last_five = data[1][0:5].lower()\n",
    "    pageNumb = 1\n",
    "    table = None\n",
    "    #while (table is None and pageNumb > 0):\n",
    "    time.sleep(3.5)\n",
    "    url = \"https://www.hockey-reference.com/players/\" + last_one + \"/\" + last_five + first_two + \"0\" + str(pageNumb) + \".html\"\n",
    "    print(url)\n",
    "    response =requests.get(url.format())\n",
    "    soup=BeautifulSoup(response.content, 'html.parser')\n",
    "    strong = soup.find('strong',string=\"Position\")\n",
    "    if strong:\n",
    "        new_strong = str(strong.next_sibling.text.split(\" \")[1])\n",
    "        new_strong = new_strong[0]\n",
    "    if new_strong == 'R':\n",
    "        new_strong = 'RW'\n",
    "    elif new_strong == 'L':\n",
    "        new_strong = 'LW'\n",
    "    new_strong = [new_strong]\n",
    "    #rows.append(strong.next_sibling)\n",
    "    table = soup.find('table', id=\"stats_basic_plus_nhl\")\n",
    "    pageNumb -= 1\n",
    "    if table is not None:\n",
    "        for i, row in enumerate(table.find_all('tr')):\n",
    "            if i == 0 or i == 1:\n",
    "                header = [el.text.strip() for el in row.find_all('th')]\n",
    "            else:\n",
    "                years = [el.text.strip() for el in row.find_all('th')]\n",
    "                player = [el.text.strip() for el in row.find_all('td')]\n",
    "                final_rows.append(new_strong + years + player)\n",
    "    l = \"\"\n",
    "    repeat_player = \"\"\n",
    "    if (len(final_rows)>0) and len(final_rows[0])==31:\n",
    "        for e in final_rows:\n",
    "            if e[2] != \"\":\n",
    "                t1,t2,t3 = injury_calc(data[0],data[1], e[1],total_player_list)\n",
    "                cols.append([data[0], data[1], e[0],e[1],e[2],e[3],e[4],e[5],e[6],e[7],e[8],e[9],e[10],e[11],e[12],e[13],e[14],e[15],\n",
    "                e[16],e[17],e[18],e[19],e[20],e[21],e[22],e[23],e[24],e[25],e[26],e[27],e[28],e[29],e[30],str(t1)[1:-1],t2,str(t3)[1:-1]])\n",
    "                #if int(t2) > 0 and e[1] == \"2021-22\":\n",
    "                    #year_data.append(player_first_name[name], player_last_name[name],e)\n",
    "                #if int(t2) <= 0:\n",
    "                    #del new_rows[-1]\n",
    "    final_rows = []\n",
    "#l,repeat_player,t2,new_rows = check_duplicates(l,repeat_player,player_first_name,player_last_name,cols,season)\n",
    "#/////////////////////////////////////////\n",
    "# Title: pandas.DataFrame.to_csv\n",
    "# Name: N/A\n",
    "# Site Owner: Pandas\n",
    "# Date: N/A\n",
    "# Code-Version: 2.1.3\n",
    "# Availability: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html\n",
    "# Modified: Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d89bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hockey_year = \"2021-22\"\n",
    "year_skaters = \"20\" + hockey_year[5:7]\n",
    "yearlyURL =  \"https://www.hockey-reference.com/leagues/NHL_\" + year_skaters + \"_skaters.html\"\n",
    "yearly_dataset = []\n",
    "stats_array = []\n",
    "response =requests.get(yearlyURL.format())\n",
    "soup=BeautifulSoup(response.content, HTML_PARSER)\n",
    "table = soup.find('table', id=\"stats\")\n",
    "for i, row in enumerate(table.find_all('tr')):\n",
    "    if i > 1:\n",
    "        yearly_dataset.append([el.text.strip() for el in row.find_all('td')])\n",
    "stats_array = convert_array(yearly_dataset,hockey_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844d7352",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rows_above_zero = []\n",
    "new_player_data = []\n",
    "for e in cols:\n",
    "    if int(e[34]) > 0:\n",
    "        rows_above_zero.append(e)\n",
    "        if e[3] == hockey_year:\n",
    "            year_data_above_zero.append(e)\n",
    "        else:\n",
    "            new_rows_above_zero.append(e)\n",
    "    if e[3] != hockey_year:\n",
    "        new_player_data.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbe379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_array = check_duplicates(stats_array)\n",
    "control_group = []\n",
    "control_group = create_control_group(stats_array,year_data_above_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802e44ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "all_players = []\n",
    "no_dup_players = []\n",
    "new_player_data =check_duplicates(new_player_data)\n",
    "\n",
    "new_rows_above_zero = check_duplicates(new_rows_above_zero)\n",
    "year_data_above_zero = check_duplicates(year_data_above_zero)\n",
    "\n",
    "to_csv(new_player_data,\"player_data.csv\")\n",
    "to_csv(new_rows_above_zero,\"player_injuries.csv\")\n",
    "to_csv(control_group,\"yearly_data.csv\")\n",
    "to_csv(year_data_above_zero,\"yearly_data_above_zero.csv\")\n",
    "print(\"finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
